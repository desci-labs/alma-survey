{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478cf05b",
   "metadata": {},
   "source": [
    "======================== Import Packages =========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ee0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pdb\n",
    "import numpy as np\n",
    "from astropy.table import Table, vstack, Column, join\n",
    "import calc_dust_masses\n",
    "import csv\n",
    "from lifelines import KaplanMeierFitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f336e",
   "metadata": {},
   "source": [
    "========================== Define Fuctions =========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d429539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_usc(f1, f2):\n",
    "\n",
    "    \"\"\"\n",
    "    PURPOSE:    Create table for Upper Sco with info needed to run the \n",
    "                two-sample tests and the KME for comparing regions\n",
    "\n",
    "                Calculates dust masses in same way as in Ansdell+2016\n",
    "                Replaces non-detections with 3-sigma upper limits\n",
    "    INPUT:      f1 = path to table 1 from Barenfeld+2016 (2016ApJ...827..142B)\n",
    "                f2 = path to table 4 from Barenfeld+2016 (2016ApJ...827..142B)\n",
    "\n",
    "    OUTPUT:     t = table that contains:\n",
    "                  Source names (str)\n",
    "                  Detection flags (int; 1=detection, 0=non-detection)\n",
    "                  Dust masses with non-detections set to 3-sigma upper limits\n",
    "                  Continuum fluxes with non-detections set to 3-sigma upper limits\n",
    "                  Stellar masses and spectral types\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### GRAB UPPER SCO DATA\n",
    "    t1 = Table.read(f1, format='ascii.cds')\n",
    "    t2 = Table.read(f2, format='ascii.cds')\n",
    "    t = join(t1, t2, join_type='inner')\n",
    "    t['Source'].name = 'Name'\n",
    "\n",
    "    ### FLAG (NON-)DETECTIONS\n",
    "    ### REPLACE NON-DETECTION FLUXES WITH 3-SIGMA UPPER LIMITS\n",
    "    t['det'] = np.repeat(0, len(t))\n",
    "    t['det'][t['Snu'] / t['e_Snu'] >= 3.0] = 1\n",
    "    t['Snu'][np.where(t['det'] == 0)] = 3.0 * t['e_Snu'][np.where(t['det'] == 0)]\n",
    "    \n",
    "    ### ONLY KEEP MSTAR >= 0.1\n",
    "    t = t[np.where(10**t['logM'] >= 0.1)]\n",
    "\n",
    "    ### CALCULATE DUST MASSES USING SAME METHOD AS LUPUS\n",
    "    mdust = []\n",
    "    for i, val in enumerate(t):\n",
    "        mdust.append(calc_dust_masses.get_dustmass(1.0, 880., t['Snu'][i], 145., 20.))\n",
    "    t['MDust'] = mdust\n",
    "\n",
    "    ### ONLY KEEP \"PRIMORDIAL\" DISKS \n",
    "    ### TO MATCH SAMPLES OF LUPUS & TAURUS\n",
    "    t = t[np.where( (t['Type'] == 'Full') | (t['Type'] == 'Transitional') | (t['Type'] == 'Evolved'))] \n",
    "\n",
    "    ### CLEAN UP\n",
    "    t['Snu'].name = 'FCont'\n",
    "    t['Mstar'] = 10**t['logM']\n",
    "\n",
    "    return t['Name', 'SpT', 'Mstar', 'FCont', 'MDust', 'det']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3931d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lup(f1, f2):\n",
    "\n",
    "    \"\"\"\n",
    "    PURPOSE:    Create table for Lupus with info needed to run the \n",
    "                two-sample tests and the KME for comparing regions\n",
    "\n",
    "                Calculates dust masses in same way as in Ansdell+2016\n",
    "                Replaces non-detections with 3-sigma upper limits\n",
    "\n",
    "    INPUT:      f1 = path to table 1 from Ansdell+2016 (2016ApJ...828...46A)\n",
    "                f2 = path to table 2 from Ansdell+2016 (2016ApJ...828...46A)\n",
    "\n",
    "    OUTPUT:     t = table that contains:\n",
    "                  Source names (str)\n",
    "                  Detection flags (int; 1=detection, 0=non-detection)\n",
    "                  Dust masses with non-detections set to 3-sigma upper limits\n",
    "                  Continuum fluxes with non-detections set to 3-sigma upper limits\n",
    "                  Stellar masses and spectral types\n",
    "                  Distances\n",
    "    \"\"\"\n",
    "\n",
    "    t1 = Table.read(f1, format='ascii.cds')\n",
    "    t2 = Table.read(f2, format='ascii.cds')\n",
    "    t = join(t1, t2, join_type='inner')\n",
    "\n",
    "    ### ONLY KEEP KNOWN STELLAR MASSES\n",
    "    t = t[~t['Mass'].mask]\n",
    "\n",
    "    ### ONLY KEEP MSTAR >= 0.1\n",
    "    t = t[t['Mass'] >= 0.1]\n",
    "\n",
    "    ### FLAG (NON-)DETECTIONS\n",
    "    ### REPLACE NON-DETECTION FLUXES WITH 3-SIGMA UPPER LIMITS\n",
    "    t['det'] = np.repeat(0, len(t))\n",
    "    t['det'][t['FCont'] / t['e_FCont'] >= 3.0] = 1\n",
    "    t['MDust'][np.where(t['det'] == 0)] = 3.0 * t['e_MDust'][np.where(t['det'] == 0)]\n",
    "\n",
    "    ### CLEAN UP\n",
    "    t['Mass'].name = 'Mstar'\n",
    "    t['SpType'].name = 'SpT'\n",
    "\n",
    "    return t['Name', 'SpT', 'Mstar', 'FCont', 'MDust', 'det', 'Dis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ae420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tau(f1, f2, f3):\n",
    "\n",
    "    \"\"\"\n",
    "    PURPOSE:    Create table for Taurus with info needed to run the \n",
    "                two-sample tests and the KME for comparing regions\n",
    "\n",
    "                Calculates dust masses in same way as in Ansdell+2016\n",
    "                Replaces non-detections with 3-sigma upper limits\n",
    "\n",
    "    INPUT:      f1 = path to table 2 from Andrews+2013 (2013ApJ...771..129A)\n",
    "                f2 = path to table 3 from Andrews+2013 (2013ApJ...771..129A)\n",
    "                f2 = path to table 4 from Andrews+2013 (2013ApJ...771..129A)\n",
    "\n",
    "    OUTPUT:     t = table that contains:\n",
    "                  Source names (str)\n",
    "                  Detection flags (int; 1=detection, 0=non-detection)\n",
    "                  Dust masses with non-detections set to 3-sigma upper limits\n",
    "                  Continuum fluxes with non-detections set to 3-sigma upper limits\n",
    "                  Stellar masses and spectral types\n",
    "                  Flag for observations at 890 or 1300 microns\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### GET STELLAR MASSES\n",
    "    name1, mstar = [], []\n",
    "    with open(f2, newline='') as f:\n",
    "\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for i, row in enumerate(reader):\n",
    "            if (i >= 6) & (i <= 217):\n",
    "\n",
    "                ### REMOVE FOOTNOTES FROM NAMES\n",
    "                row[0] = row[0].split('^')[0]\n",
    "\n",
    "                ### THESE SOURCES HAD DIFFERENT NAMES IN OTHER TABLE\n",
    "                if row[0] == 'JH 112 Aa':\n",
    "                    row[0] = 'JH 112 A'\n",
    "                if row[0] == 'JH 112 Ab':\n",
    "                    row[0] = 'JH 112 B'\n",
    "\n",
    "                ### THESE SOURCES ARE NOT IN OTHER TABLES\n",
    "                if row[0] in ['J04361030+2159364', 'J04263055+2443558', 'J04335245+2612548', 'J04290068+2755033']:\n",
    "                    continue\n",
    "\n",
    "                ### THIS SOURCE WAS SEPARATED IN A & B COMPONENTS IN OTHER TABLE\n",
    "                if row[0] == 'CIDA 11 AB':\n",
    "                    row[0] = ['CIDA 11 A', 'CIDA 11 B']\n",
    "                    row[9] = [row[9], row[9]]\n",
    "                else:\n",
    "                    ### SO ALL OTHERS ARE ALSO LISTS; NEEDED FOR EXTEND FUNCTION BELOW\n",
    "                    row[0] = row[0].split(';')\n",
    "                    row[9] = row[9].split(';')\n",
    "\n",
    "                ### ADD TO LIST\n",
    "                name1.extend(row[0])\n",
    "                mstar.extend(row[9])\n",
    "\n",
    "    ### GET FLUXES AND SPECTRAL TYPES\n",
    "    name2, spt, f890, f1300, det890, det1300, note = [], [], [], [], [], [], []\n",
    "    with open(f1, newline='') as f:\n",
    "        \n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for i, row in enumerate(reader):\n",
    "            if (i >= 6) & (i <= 215):\n",
    "\n",
    "                ### THESE SOURCES ARE NOT IN OTHER TABLE\n",
    "                if row[0] in ['J04290068+2755033']:\n",
    "                    continue\n",
    "\n",
    "                ### GET SPECTRAL TYPE\n",
    "                if '(' in row[1]:\n",
    "                    row[1] = row[1].split('-')[0][1:]\n",
    "                spt.append(row[1].split(', ')[0].split(' +or- ')[0])\n",
    "\n",
    "                ### GET NAME\n",
    "                name2.append(row[0].split('^')[0])\n",
    "\n",
    "                ### GET FLUXES AND FLAG DETECTIONS\n",
    "                f890.append(row[3].split(' +or- ')[0].split('<')[-1])\n",
    "                if '<' in row[3]:\n",
    "                    det890.append(0)\n",
    "                else:\n",
    "                    det890.append(1)\n",
    "                f1300.append(row[4].split(' +or- ')[0].split('<')[-1])\n",
    "                if '<' in row[4]:\n",
    "                    det1300.append(0)\n",
    "                else:\n",
    "                    det1300.append(1)\n",
    "\n",
    "                ### GET NOTE ON OBSERVED OR EXTRAPOLATED\n",
    "                note.append(row[5])                \n",
    "\n",
    "    ### CREATE TABLE\n",
    "    t = Table()\n",
    "    t['Name'] = name1\n",
    "    t['F890'] = np.array(f890).astype(float) * 1e3\n",
    "    t['F1300'] = np.array(f1300).astype(float) * 1e3\n",
    "    t['det890'] = det890\n",
    "    t['det1300'] = det1300\n",
    "    t['Mstar'] = 10**np.array(mstar).astype(float)\n",
    "    t['SpT'] = spt\n",
    "\n",
    "    ### FIGURE OUT WHICH WERE MEASURED AT WHAT WAVELENGTH\n",
    "    otype = np.empty(len(t), dtype='U10')\n",
    "    for i, val in enumerate(note):\n",
    "        test = val.split(\", \")\n",
    "        if (test[0] == 'm') or (test[0] == '(m'): \n",
    "            otype[i] = 890\n",
    "        else: \n",
    "            otype[i] = 1300\n",
    "    t['ObsType'] = otype\n",
    "\n",
    "    ### ONLY KEEP MSTAR >= 0.1\n",
    "    t = t[t['Mstar'] >= 0.1]\n",
    "\n",
    "    # ### REMOVE BINARIES\n",
    "    # ### SINCE LUPUS AND UPPER SCO SAMPLES DIDN'T INCLUDE SECONDARY SOURCES\n",
    "    # ind_bin = []\n",
    "    # for i, val in enumerate(t['Name']):\n",
    "    #     if i == 0:\n",
    "    #         continue\n",
    "    #     if (' B' in t['Name'][i]) & (' A' in t['Name'][i-1]):\n",
    "    #         ind_bin.append(i)\n",
    "    #     if val == 'UZ Tau Wb':\n",
    "    #         ind_bin.append(i)\n",
    "    # t.remove_rows(ind_bin)\n",
    "\n",
    "    ### CALCULATE DUST MASSES USING SAME METHOD AS Ansdell+2016\n",
    "    mdust, det, fcont = [], [], []\n",
    "    for i, val in enumerate(t['ObsType']):\n",
    "        if val == '890':\n",
    "            mdust.append(calc_dust_masses.get_dustmass(1.0, 890., t['F890'][i], 140., 20.))\n",
    "            det.append(t['det890'][i])\n",
    "            fcont.append(t['F890'][i])\n",
    "        elif val == '1300':\n",
    "            mdust.append(calc_dust_masses.get_dustmass(1.0, 1300., t['F1300'][i], 140., 20.))\n",
    "            det.append(t['det1300'][i])\n",
    "            fcont.append(t['F1300'][i])\n",
    "    t['MDust'] = mdust\n",
    "    t['det'] = det\n",
    "    t['FCont'] = fcont\n",
    "\n",
    "    return t['Name', 'SpT', 'Mstar', 'FCont', 'MDust', 'det', 'ObsType']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2cdac1",
   "metadata": {},
   "source": [
    "============================= Code =================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LOAD IN TABLES \n",
    "TL = get_lup('../input/apjaa2846t1_mrf.txt', '../input/apjaa2846t2_mrf.txt')\n",
    "TU = get_usc('../input/apjaa2b81t1_mrt.txt', '../input/apjaa2b81t4_mrt.txt')\n",
    "TT = get_tau('../input/apj476413t2_ascii.txt', '../input/apj476413t3_ascii.txt', '../input/apj476413t4_ascii.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96c000",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "### WRITE FILES\n",
    "TL.write('../output/data_lup.txt', format='ascii.ipac')\n",
    "TU.write('../output/data_usc.txt', format='ascii.ipac')\n",
    "TT.write('../output/data_tau.txt', format='ascii.ipac')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
